{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1E58CgB-upC9SnTWGsl1ipLEY65vjN1rK",
      "authorship_tag": "ABX9TyMFNw3clV7EG5XL7HPcE8u/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohkharma/Credit-Card-Fraud-Detection-Using-Machine-Learning-Comparative-Study/blob/main/credit_card_fraud_detection_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Credit-Card-Fraud-Detection-Using-Machine-Learning-Comparative-Study**\n",
        "Author: Mohammed Kharma, Feb-2023\n",
        "\n",
        "\n",
        "This book is using the dataset taken from:\n",
        "\n",
        "[Credit Card Fraud on Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)\n",
        "\n"
      ],
      "metadata": {
        "id": "SOLHwpf8xgFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "h_8HXd21yb9r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsGW8CMUvL-c"
      },
      "outputs": [],
      "source": [
        "#Importing the required libraries:\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the dataset into DataFrame using pandas\n",
        "\n",
        "credit_card_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/creditcard.csv')"
      ],
      "metadata": {
        "id": "X0-yv_6Xvdfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset informations\n",
        "credit_card_data.info()"
      ],
      "metadata": {
        "id": "3d1YXuddysw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# head 5 rows of the dataset\n",
        "credit_card_data.head()"
      ],
      "metadata": {
        "id": "gGvNYukl00hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tail 5 rows of the dataset\n",
        "credit_card_data.tail()"
      ],
      "metadata": {
        "id": "m6HNsa-p02Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset description\n",
        "credit_card_data.describe()"
      ],
      "metadata": {
        "id": "j1_VJly803Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# missing values in each column check\n",
        "credit_card_data.isnull().sum()"
      ],
      "metadata": {
        "id": "0pNEaETpzBRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of the data\n",
        "credit_card_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i9LJvJL05aN",
        "outputId": "e7d94cbc-b7cd-4364-9a09-f761a6dd5162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 522
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# legit and fraudulent transactions per class\n",
        "credit_card_data['Class'].value_counts()"
      ],
      "metadata": {
        "id": "WCgZJN0Ty_ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the data for analysis\n",
        "legit = credit_card_data[credit_card_data.Class == 0]\n",
        "fraud = credit_card_data[credit_card_data.Class == 1]\n",
        "\n",
        "print(legit.shape)\n",
        "print(fraud.shape)"
      ],
      "metadata": {
        "id": "deYNlEWdzJ91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# statistical measures of the data\n",
        "legit.Amount.describe()"
      ],
      "metadata": {
        "id": "5F88_eO1zOEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud.Amount.describe()"
      ],
      "metadata": {
        "id": "fGf8Vyd25tE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the values for both transactions so we can compare the generated sample from the legitmite df where it need to refelect relevint means\n",
        "credit_card_data.groupby('Class').mean()"
      ],
      "metadata": {
        "id": "YItGvmUZzVzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under-Sampling\n",
        "\n",
        "Build a sample dataset containing similar distribution of normal transactions and Fraudulent Transactions\n",
        "\n",
        "Number of Fraudulent Transactions --> 492"
      ],
      "metadata": {
        "id": "GvFtJWvPzao-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#legit_test = legit.sample(n=2000)\n",
        "legit_test = legit.iloc[0:2001,0:32]\n",
        "legit = legit.iloc[2002:,0:32]"
      ],
      "metadata": {
        "id": "Pyz7erKN7drV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "legit_sample = legit.sample(n=492)"
      ],
      "metadata": {
        "id": "Pgtv5Z3NzcpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "legit_sample.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDJ-rnEl71vs",
        "outputId": "0e3e7bc1-d979-44b0-b1bc-3ee77d8dd15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(492, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 530
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "legit_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "g9NK5TfU8XNu",
        "outputId": "25ce47bd-de14-473b-ddda-62112dd2f516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Time        V1        V2        V3        V4        V5        V6  \\\n",
              "0        0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
              "1        0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
              "2        1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "3        1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
              "4        2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "1998  1542.0  1.194910  0.093867 -0.073016  1.008538  0.454666  0.809557   \n",
              "1999  1542.0 -0.090760  0.430191  0.587889 -1.468904  0.315714 -0.765142   \n",
              "2000  1544.0 -0.781938  1.594474  2.067660  1.823249  0.260623 -0.502556   \n",
              "2001  1545.0 -0.693979  0.863780  1.782080 -0.621203 -0.034457 -0.556248   \n",
              "2002  1545.0 -1.739979  1.107891  0.591365 -0.767648  0.060833 -0.427431   \n",
              "\n",
              "            V7        V8        V9  ...       V21       V22       V23  \\\n",
              "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
              "1    -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
              "2     0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
              "3     0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
              "4     0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1998 -0.069582  0.219049  0.146503  ... -0.126805 -0.180904 -0.220110   \n",
              "1999  0.737765 -0.348267 -1.877661  ...  0.238175  0.619908 -0.381979   \n",
              "2000  1.090112 -0.490576 -1.142105  ... -0.113361 -0.411819  0.006180   \n",
              "2001  0.704357  0.061961 -0.290994  ... -0.124982 -0.122718 -0.158336   \n",
              "2002  0.248729  0.476310  0.611437  ... -0.343057 -0.602356  0.039468   \n",
              "\n",
              "           V24       V25       V26       V27       V28  Amount  Class  \n",
              "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1    -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2    -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3    -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
              "...        ...       ...       ...       ...       ...     ...    ...  \n",
              "1998 -1.134723  0.779307 -0.257532  0.032098 -0.005676   13.08      0  \n",
              "1999 -0.387806  0.492030 -0.078039  0.023719  0.036965   25.00      0  \n",
              "2000  0.681210 -0.286224 -0.412347 -0.663629 -0.134151    9.35      0  \n",
              "2001  0.590370 -0.014215  0.344616  0.284906  0.157360    5.00      0  \n",
              "2002 -0.582638  0.300574  0.456637  0.323645  0.152760    5.00      0  \n",
              "\n",
              "[2001 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cccce3be-6e9c-475e-8098-80795e06d453\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1542.0</td>\n",
              "      <td>1.194910</td>\n",
              "      <td>0.093867</td>\n",
              "      <td>-0.073016</td>\n",
              "      <td>1.008538</td>\n",
              "      <td>0.454666</td>\n",
              "      <td>0.809557</td>\n",
              "      <td>-0.069582</td>\n",
              "      <td>0.219049</td>\n",
              "      <td>0.146503</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.126805</td>\n",
              "      <td>-0.180904</td>\n",
              "      <td>-0.220110</td>\n",
              "      <td>-1.134723</td>\n",
              "      <td>0.779307</td>\n",
              "      <td>-0.257532</td>\n",
              "      <td>0.032098</td>\n",
              "      <td>-0.005676</td>\n",
              "      <td>13.08</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1542.0</td>\n",
              "      <td>-0.090760</td>\n",
              "      <td>0.430191</td>\n",
              "      <td>0.587889</td>\n",
              "      <td>-1.468904</td>\n",
              "      <td>0.315714</td>\n",
              "      <td>-0.765142</td>\n",
              "      <td>0.737765</td>\n",
              "      <td>-0.348267</td>\n",
              "      <td>-1.877661</td>\n",
              "      <td>...</td>\n",
              "      <td>0.238175</td>\n",
              "      <td>0.619908</td>\n",
              "      <td>-0.381979</td>\n",
              "      <td>-0.387806</td>\n",
              "      <td>0.492030</td>\n",
              "      <td>-0.078039</td>\n",
              "      <td>0.023719</td>\n",
              "      <td>0.036965</td>\n",
              "      <td>25.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>1544.0</td>\n",
              "      <td>-0.781938</td>\n",
              "      <td>1.594474</td>\n",
              "      <td>2.067660</td>\n",
              "      <td>1.823249</td>\n",
              "      <td>0.260623</td>\n",
              "      <td>-0.502556</td>\n",
              "      <td>1.090112</td>\n",
              "      <td>-0.490576</td>\n",
              "      <td>-1.142105</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.113361</td>\n",
              "      <td>-0.411819</td>\n",
              "      <td>0.006180</td>\n",
              "      <td>0.681210</td>\n",
              "      <td>-0.286224</td>\n",
              "      <td>-0.412347</td>\n",
              "      <td>-0.663629</td>\n",
              "      <td>-0.134151</td>\n",
              "      <td>9.35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001</th>\n",
              "      <td>1545.0</td>\n",
              "      <td>-0.693979</td>\n",
              "      <td>0.863780</td>\n",
              "      <td>1.782080</td>\n",
              "      <td>-0.621203</td>\n",
              "      <td>-0.034457</td>\n",
              "      <td>-0.556248</td>\n",
              "      <td>0.704357</td>\n",
              "      <td>0.061961</td>\n",
              "      <td>-0.290994</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.124982</td>\n",
              "      <td>-0.122718</td>\n",
              "      <td>-0.158336</td>\n",
              "      <td>0.590370</td>\n",
              "      <td>-0.014215</td>\n",
              "      <td>0.344616</td>\n",
              "      <td>0.284906</td>\n",
              "      <td>0.157360</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>1545.0</td>\n",
              "      <td>-1.739979</td>\n",
              "      <td>1.107891</td>\n",
              "      <td>0.591365</td>\n",
              "      <td>-0.767648</td>\n",
              "      <td>0.060833</td>\n",
              "      <td>-0.427431</td>\n",
              "      <td>0.248729</td>\n",
              "      <td>0.476310</td>\n",
              "      <td>0.611437</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.343057</td>\n",
              "      <td>-0.602356</td>\n",
              "      <td>0.039468</td>\n",
              "      <td>-0.582638</td>\n",
              "      <td>0.300574</td>\n",
              "      <td>0.456637</td>\n",
              "      <td>0.323645</td>\n",
              "      <td>0.152760</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2001 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cccce3be-6e9c-475e-8098-80795e06d453')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cccce3be-6e9c-475e-8098-80795e06d453 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cccce3be-6e9c-475e-8098-80795e06d453');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 531
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenating two DataFrames"
      ],
      "metadata": {
        "id": "M6V0tuWPziKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = pd.concat([legit_sample, fraud], axis=0)"
      ],
      "metadata": {
        "id": "U6QtjL4gzgkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset.head()\n",
        "new_dataset.tail()\n",
        "new_dataset['Class'].value_counts()\n",
        "new_dataset.groupby('Class').mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "tVkSy40mzoci",
        "outputId": "5d607302-8b1f-447b-875d-44f6bd2f767a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Time        V1        V2        V3        V4        V5  \\\n",
              "Class                                                                   \n",
              "0      96224.725610  0.002366  0.075517  0.023714  0.059047  0.104433   \n",
              "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
              "\n",
              "             V6        V7        V8        V9  ...       V20       V21  \\\n",
              "Class                                          ...                       \n",
              "0     -0.050490  0.010652 -0.029354 -0.001286  ... -0.083836 -0.045855   \n",
              "1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n",
              "\n",
              "            V22       V23       V24       V25       V26       V27       V28  \\\n",
              "Class                                                                         \n",
              "0      0.051065  0.001702 -0.029183  0.014025  0.010112  0.008844 -0.028621   \n",
              "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
              "\n",
              "           Amount  \n",
              "Class              \n",
              "0       64.140305  \n",
              "1      122.211321  \n",
              "\n",
              "[2 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-276f188f-d02d-412a-98c0-c67712af313c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96224.725610</td>\n",
              "      <td>0.002366</td>\n",
              "      <td>0.075517</td>\n",
              "      <td>0.023714</td>\n",
              "      <td>0.059047</td>\n",
              "      <td>0.104433</td>\n",
              "      <td>-0.050490</td>\n",
              "      <td>0.010652</td>\n",
              "      <td>-0.029354</td>\n",
              "      <td>-0.001286</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.083836</td>\n",
              "      <td>-0.045855</td>\n",
              "      <td>0.051065</td>\n",
              "      <td>0.001702</td>\n",
              "      <td>-0.029183</td>\n",
              "      <td>0.014025</td>\n",
              "      <td>0.010112</td>\n",
              "      <td>0.008844</td>\n",
              "      <td>-0.028621</td>\n",
              "      <td>64.140305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80746.806911</td>\n",
              "      <td>-4.771948</td>\n",
              "      <td>3.623778</td>\n",
              "      <td>-7.033281</td>\n",
              "      <td>4.542029</td>\n",
              "      <td>-3.151225</td>\n",
              "      <td>-1.397737</td>\n",
              "      <td>-5.568731</td>\n",
              "      <td>0.570636</td>\n",
              "      <td>-2.581123</td>\n",
              "      <td>...</td>\n",
              "      <td>0.372319</td>\n",
              "      <td>0.713588</td>\n",
              "      <td>0.014049</td>\n",
              "      <td>-0.040308</td>\n",
              "      <td>-0.105130</td>\n",
              "      <td>0.041449</td>\n",
              "      <td>0.051648</td>\n",
              "      <td>0.170575</td>\n",
              "      <td>0.075667</td>\n",
              "      <td>122.211321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-276f188f-d02d-412a-98c0-c67712af313c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-276f188f-d02d-412a-98c0-c67712af313c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-276f188f-d02d-412a-98c0-c67712af313c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 533
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data into Features & Targets"
      ],
      "metadata": {
        "id": "JpsnRF0Ozwha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = new_dataset.drop(columns='Class', axis=1)\n",
        "Y = new_dataset['Class']"
      ],
      "metadata": {
        "id": "7j45-uAJzwTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBWsiLmwz2Ab",
        "outputId": "3a652e16-aebc-4ec9-8f54-31d180d99b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Time        V1        V2        V3        V4        V5        V6  \\\n",
            "117840   74838.0  1.135858 -0.106367  1.001555  0.693739 -0.942031 -0.478576   \n",
            "131278   79541.0 -1.089192  1.033084  1.142932  0.272566  1.303121 -0.979236   \n",
            "246887  153375.0  0.128395  0.968289 -0.423312 -0.536925  0.853749 -0.762438   \n",
            "280607  169640.0 -0.415778  0.712262  0.690968 -0.793964 -0.239076 -0.661871   \n",
            "220254  142089.0 -0.952154  1.532240 -0.172828 -0.338676 -0.689891 -1.764746   \n",
            "...          ...       ...       ...       ...       ...       ...       ...   \n",
            "279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
            "280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
            "280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
            "281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
            "281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
            "\n",
            "              V7        V8        V9  ...       V20       V21       V22  \\\n",
            "117840 -0.483896  0.122364  0.551814  ... -0.191440 -0.045742 -0.182796   \n",
            "131278  0.796023  0.014980 -0.767905  ...  0.004609  0.047749  0.019093   \n",
            "246887  0.944355 -0.051844  0.045173  ... -0.015664 -0.338852 -0.862364   \n",
            "280607  0.098162  0.353882  0.512907  ... -0.297192  0.415782  1.302367   \n",
            "220254  0.312567  0.591175 -0.263847  ... -0.158450 -0.148905 -0.446523   \n",
            "...          ...       ...       ...  ...       ...       ...       ...   \n",
            "279863 -0.882850  0.697211 -2.064945  ...  1.252967  0.778584 -0.319189   \n",
            "280143 -1.413170  0.248525 -1.127396  ...  0.226138  0.370612  0.028234   \n",
            "280149 -2.234739  1.210158 -0.652250  ...  0.247968  0.751826  0.834108   \n",
            "281144 -2.208002  1.058733 -1.632333  ...  0.306271  0.583276 -0.269209   \n",
            "281674  0.223050 -0.068384  0.577829  ... -0.017652 -0.164350 -0.295135   \n",
            "\n",
            "             V23       V24       V25       V26       V27       V28  Amount  \n",
            "117840  0.168180  0.371522 -0.004614  0.226501 -0.000106  0.025449   17.02  \n",
            "131278 -0.342555 -0.066300  0.648471 -0.382973  0.054331  0.104612    1.00  \n",
            "246887  0.126679  0.526144 -0.456979  0.118541  0.219085  0.082937   10.02  \n",
            "280607  0.009938  0.023410 -1.003457 -0.508615  0.178509  0.203135    9.99  \n",
            "220254  0.283782  0.923558 -0.509051  0.092122  0.117019  0.026486    9.99  \n",
            "...          ...       ...       ...       ...       ...       ...     ...  \n",
            "279863  0.639419 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00  \n",
            "280143 -0.145640 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76  \n",
            "280149  0.190944  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89  \n",
            "281144 -0.456108 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00  \n",
            "281674 -0.072173 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53  \n",
            "\n",
            "[984 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpY5ZYrUz1p2",
        "outputId": "5cabec16-07a3-4046-c877-c833e56f75ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117840    0\n",
            "131278    0\n",
            "246887    0\n",
            "280607    0\n",
            "220254    0\n",
            "         ..\n",
            "279863    1\n",
            "280143    1\n",
            "280149    1\n",
            "281144    1\n",
            "281674    1\n",
            "Name: Class, Length: 984, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into Training data & Testing Data"
      ],
      "metadata": {
        "id": "ByFglL5Bz6ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5fNp37V6l7f",
        "outputId": "5b0c9a2d-959b-4a6d-8583-e84461caa54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(984, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 537
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)"
      ],
      "metadata": {
        "id": "dKZvfUrhz7Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htfsdRjez8vO",
        "outputId": "e23444b2-6933-4978-fc10-11422c9a5e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(984, 30) (787, 30) (197, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training\n",
        "\n",
        "Logistic Regression"
      ],
      "metadata": {
        "id": "B05-YEkPz-sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()"
      ],
      "metadata": {
        "id": "22s0oAGZ0ApS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the Logistic Regression Model with Training Data\n",
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ0QBB530C4m",
        "outputId": "5706bfcc-4963-4b70-a016-906fbf7e6144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 541
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation\n",
        "\n",
        "Accuracy Score"
      ],
      "metadata": {
        "id": "da7S4gQt0ErK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "\n",
        "print('Accuracy on Training data : ', training_data_accuracy)\n",
        "\n",
        "# accuracy on test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "\n",
        "print('Accuracy score on Test Data : ', test_data_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b2NqP840GnO",
        "outputId": "0548f9d3-8843-4aac-ec31-e1aa0d314df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Training data :  0.951715374841169\n",
            "Accuracy score on Test Data :  0.934010152284264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.datasets import make_classification\n",
        "# import sklearn\n",
        "# temp_dataset = pd.concat([legit, fraud], axis=0)\n",
        "# X_temp = temp_dataset.drop(columns='Class', axis=1)\n",
        "# Y_temp = temp_dataset['Class']\n",
        "\n",
        "# X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
        "#                                             n_redundant=0, n_repeated=0, n_classes=2,\n",
        "#                                             n_clusters_per_class=1,\n",
        "#                                             weights=[0.95, 0.05],\n",
        "#                                             class_sep=0.5, random_state=0)\n",
        "\n",
        "# dataset_df = pd.DataFrame({'X1':X_temp[:,0],'X2':X_temp[:,1], 'Y':Y_temp})"
      ],
      "metadata": {
        "id": "MVcMWdTiv8eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 runs preperation using dimensionality reduction, tested and it showed no change in the F1 and accuricy\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "legit = credit_card_data[credit_card_data.Class == 0]\n",
        "fraud = credit_card_data[credit_card_data.Class == 1]\n",
        "\n",
        "temp_dataset = pd.concat([legit, fraud], axis=0)\n",
        "X_temp = temp_dataset.drop(columns='Class', axis=1)\n",
        "Y_temp = temp_dataset['Class']\n",
        "\n",
        "# Initialize PCA and fit the data\n",
        "pca = PCA(n_components=2)\n",
        "X_reduced = pca.fit_transform(X_temp)\n",
        "\n",
        "# Print the explained variance ratio for each principal component\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "# Create a new dataframe with the reduced features\n",
        "df_reduced = pd.DataFrame(X_reduced, columns=['PC1', 'PC2'])\n",
        "\n",
        "# Add the target variable back to the dataframe\n",
        "df_reduced['Class'] = Y_temp\n",
        "\n",
        "legit = df_reduced[df_reduced.Class == 0]\n",
        "fraud = df_reduced[df_reduced.Class == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhXLh83UziEM",
        "outputId": "965173f5-1113-4871-aa3d-8a1315a901c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.99972249e-01 2.77382192e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10 runs \n",
        "from sklearn import ensemble\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier  # Include\n",
        "from sklearn.naive_bayes import GaussianNB   # Include\n",
        "from sklearn.svm import SVC                      # Include\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "model = LogisticRegression()     # Include\n",
        "# model = RandomForestClassifier(n_estimators=100)\n",
        "#model = GaussianNB()\n",
        "#model = SVC(kernel='linear', C=1.0)\n",
        "#model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=6)\n",
        "\n",
        "for i in range(1, 11):\n",
        "  legit_new_sample = legit.sample(n=492)\n",
        "\n",
        "  new_dataset = pd.concat([legit_new_sample, fraud], axis=0)\n",
        "  X_new = new_dataset.drop(columns='Class', axis=1)\n",
        "  Y_new = new_dataset['Class']\n",
        "\n",
        "  X_train_new, X_test_new, Y_train_new, Y_test_new = train_test_split(X_new, Y_new, test_size=0.2, stratify=Y, random_state=2)\n",
        "\n",
        "  model.fit(X_train_new, Y_train_new)\n",
        "  # accuracy on training data\n",
        "  X_train_prediction_new = model.predict(X_train_new)\n",
        "  training_data_accuracy_new = accuracy_score(X_train_prediction_new, Y_train_new)\n",
        "\n",
        "  print('Accuracy on Training data : ', training_data_accuracy_new)\n",
        "\n",
        "  # accuracy on test data\n",
        "  X_test_prediction_new = model.predict(X_test_new)\n",
        "  test_data_accuracy_new = accuracy_score(X_test_prediction_new, Y_test_new)\n",
        "\n",
        "  print(classification_report(X_test_prediction_new,Y_test_new))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDSgev2drT11",
        "outputId": "a0fbd444-7d22-479e-e8d5-77fc76fa58c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Training data :  0.5743329097839899\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.57      0.52        82\n",
            "           1       0.64      0.55      0.59       115\n",
            "\n",
            "    accuracy                           0.56       197\n",
            "   macro avg       0.56      0.56      0.56       197\n",
            "weighted avg       0.57      0.56      0.56       197\n",
            "\n",
            "Accuracy on Training data :  0.5667090216010165\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.55      0.48        76\n",
            "           1       0.65      0.53      0.58       121\n",
            "\n",
            "    accuracy                           0.54       197\n",
            "   macro avg       0.54      0.54      0.53       197\n",
            "weighted avg       0.56      0.54      0.54       197\n",
            "\n",
            "Accuracy on Training data :  0.5476493011435832\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.53      0.46        76\n",
            "           1       0.63      0.51      0.57       121\n",
            "\n",
            "    accuracy                           0.52       197\n",
            "   macro avg       0.52      0.52      0.51       197\n",
            "weighted avg       0.54      0.52      0.52       197\n",
            "\n",
            "Accuracy on Training data :  0.5336721728081322\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.55      0.54        94\n",
            "           1       0.57      0.54      0.56       103\n",
            "\n",
            "    accuracy                           0.55       197\n",
            "   macro avg       0.55      0.55      0.55       197\n",
            "weighted avg       0.55      0.55      0.55       197\n",
            "\n",
            "Accuracy on Training data :  0.5476493011435832\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.62      0.59        91\n",
            "           1       0.64      0.59      0.62       106\n",
            "\n",
            "    accuracy                           0.60       197\n",
            "   macro avg       0.60      0.60      0.60       197\n",
            "weighted avg       0.61      0.60      0.60       197\n",
            "\n",
            "Accuracy on Training data :  0.5489199491740788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.60      0.57        88\n",
            "           1       0.64      0.58      0.61       109\n",
            "\n",
            "    accuracy                           0.59       197\n",
            "   macro avg       0.59      0.59      0.59       197\n",
            "weighted avg       0.59      0.59      0.59       197\n",
            "\n",
            "Accuracy on Training data :  0.5489199491740788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.52      0.46        79\n",
            "           1       0.61      0.51      0.56       118\n",
            "\n",
            "    accuracy                           0.51       197\n",
            "   macro avg       0.51      0.51      0.51       197\n",
            "weighted avg       0.53      0.51      0.52       197\n",
            "\n",
            "Accuracy on Training data :  0.5717916137229987\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.57      0.52        82\n",
            "           1       0.64      0.55      0.59       115\n",
            "\n",
            "    accuracy                           0.56       197\n",
            "   macro avg       0.56      0.56      0.56       197\n",
            "weighted avg       0.57      0.56      0.56       197\n",
            "\n",
            "Accuracy on Training data :  0.5209656925031766\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.54      0.49        82\n",
            "           1       0.61      0.52      0.56       115\n",
            "\n",
            "    accuracy                           0.53       197\n",
            "   macro avg       0.53      0.53      0.52       197\n",
            "weighted avg       0.54      0.53      0.53       197\n",
            "\n",
            "Accuracy on Training data :  0.5552731893265566\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.59      0.55        86\n",
            "           1       0.64      0.57      0.60       111\n",
            "\n",
            "    accuracy                           0.58       197\n",
            "   macro avg       0.58      0.58      0.58       197\n",
            "weighted avg       0.59      0.58      0.58       197\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QIKRl-OZv4PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76Z9afyh-AJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 Flods\n",
        "# from sklearn.model_selection import KFold\n",
        "# import numpy as np\n",
        "\n",
        "# # Define the number of folds\n",
        "# num_folds = 10\n",
        "\n",
        "\n",
        "# # Generate some example data\n",
        "# X = credit_card_data.drop(columns='Class', axis=1).values\n",
        "# y = credit_card_data['Class'].values\n",
        "\n",
        "# # Create a KFold object to split the data\n",
        "# kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# # Iterate over each fold\n",
        "# for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "#     # Get the training and testing data for this fold\n",
        "#     X_train, X_test = X[train_index], X[test_index]\n",
        "#     y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "#     # Train your model on the training data\n",
        "#     model.fit(X_train, y_train)\n",
        "    \n",
        "#     # Test your model on the testing data\n",
        "#     accuracy = model.score(X_test, y_test)\n",
        "    \n",
        "#     # Print out the accuracy for this fold\n",
        "#     print(f\"Fold {fold+1}: accuracy = {accuracy}\")\n"
      ],
      "metadata": {
        "id": "GpydCjRgpCUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(X_test_prediction,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX5GMMX_lsFT",
        "outputId": "b6c5f0d8-2fa4-44fa-e159-30f0462942c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.94       104\n",
            "           1       0.91      0.96      0.93        93\n",
            "\n",
            "    accuracy                           0.93       197\n",
            "   macro avg       0.93      0.94      0.93       197\n",
            "weighted avg       0.94      0.93      0.93       197\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "\n",
        "print('Accuracy on Training data : ', training_data_accuracy)\n",
        "\n",
        "# accuracy on test data\n",
        "X_test_prediction = model.predict(legit_test.drop(columns='Class', axis=1))\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, legit_test['Class'])\n",
        "\n",
        "print('Accuracy score on Test Data : ', test_data_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "\n",
        "actual = legit_test['Class']\n",
        "predicted = X_test_prediction\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()\n",
        "\n",
        "# X1 = legit_test.drop(columns='Class', axis=1)\n",
        "# Y1 = legit_test['Class']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "QuS7AQzqnIBN",
        "outputId": "68a9602e-e0c5-408f-d797-c9387e7869d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names unseen at fit time:\n",
            "- Amount\n",
            "- Time\n",
            "- V1\n",
            "- V10\n",
            "- V11\n",
            "- ...\n",
            "Feature names seen at fit time, yet now missing:\n",
            "- PC1\n",
            "- PC2\n",
            "\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-548-fdeffc6fbb65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# accuracy on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtraining_data_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy on Training data : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 30 features, but LogisticRegression is expecting 2 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jGEMNXsWnHwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate F1 score on imbalanced dataset\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(actual,predicted))"
      ],
      "metadata": {
        "id": "MXw6hJaWk8UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dPup-WLCk8DC"
      }
    }
  ]
}